{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1>Registre national des entreprises (RNE)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ce registre vient de [l'Institut National de la Propriété Industrielle](https://data.inpi.fr/) qui donne accès à de nombreuses données sur les entreprises.\n",
    "\n",
    "Les données peuvent être consultées sur le web, sur le serveur de l'INPI ou par API. Il aurait été pratique d'utiliser l'API pour des questions de facilité de prise en main, de mise à jour des données etc ...\n",
    "\n",
    "Néanmoins la [documentation officielle](https://www.inpi.fr/sites/default/files/documentation_technique_API_formalit%C3%A9s_v2.5.pdf) indique qu'il est impossible de filtrer géographiquement les établissements dans les méthodes GET et impose une limite de 10 Go / jour / utilisateur, ce qui est bloquant pour notre application.\n",
    "\n",
    "On va donc utiliser les serveurs et télécharger les donnéees avec le protocole FTP.\n",
    "\n",
    "Pour cela, il faut créer un compte INPI et faire la demande pour avoir les accès.\n",
    "\n",
    "Une fois le compte crée, on peut accéder au serveur FTP de l'INPI (voir [ici](https://data.inpi.fr/content/editorial/Serveur_ftp_entreprises)).\n",
    "\n",
    "Les données user_id / mdp sont retrouvables sur [ce lien](https://data.inpi.fr/espace_personnel/acces).\n",
    "\n",
    "On télécharge le registre des Créations, modifications, cessations (CMC) d'entreprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Téléchargement\n",
    "\n",
    "Pour le télécharger, on peut s'inspirer du **code suivant** :\n",
    "\n",
    "```bash\n",
    "# connexion au serveur ftp de l'inpi\n",
    "sftp user_id@www.inpi.net\n",
    "\n",
    "# accepter la connexion et rentrer le mot de passe\n",
    "\n",
    "# création d'un dossier sur la machine locale\n",
    "lmkdir rne\n",
    "\n",
    "# navigation dans ce dossier \n",
    "llcd rne\n",
    "\n",
    "# téléchargement des fichiers\n",
    "get stock RNE formalité.zip \n",
    "\n",
    "# le téléchargement dure 15 min environ\n",
    "\n",
    "# décompression des données\n",
    "unzip stock RNE formalité.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nettoyage des données\n",
    "\n",
    "Les données obtenues sont une collection de jsons, on aimerait pouvoir les retraiter pour pouvoir les utiliser plus efficacement, il faut :\n",
    "\n",
    "**2.1 destructurer les informations pour aller à la maille des établissements** \n",
    "\n",
    "On différencie ici les entreprise (identifiées par leur SIREN) des établissements (identifiées par leur SIRET = SIREN + NIC), plus d'infos [ici](https://entreprendre.service-public.fr/vosdroits/F32135#:~:text=Siret%20signifie%20Syst%C3%A8me%20d'identification,num%C3%A9ro%20interne%20de%20classement%20Insee).\n",
    "\n",
    "**2.2 ne garder que les infos pertinentes, à savoir à la maille d'un établissement** :\n",
    "\n",
    "- **siret** : code d'identification d'un établissement. On distingue ici les entreprises (identifiées par leur numéro SIREN) des établissements (SIRET = SIREN + NIC)\n",
    "- **codeApe** : activité principale de l'établissement renseignée à l'INPI\n",
    "- **codeInseeCommune** : code de la commune pour pouvoir localiser les entreprises\n",
    "- **nomCommercial** : nom de l'entreprise \n",
    "- **diffusionCommerciale** : oui / non \n",
    "- **adresse** : l'adresse de l'établissement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion des json en parquet\n",
    "\n",
    "Pour accélerer le temps de traitement des fichiers et prendre moins de stockage, on convertit tous les json en parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "base_path = \"../../rne/rne_deflated\"\n",
    "\n",
    "\n",
    "# convert json to parquet\n",
    "def convert_json_to_parquet(json_path, parquet_path):\n",
    "\n",
    "    # read json\n",
    "    with open(json_path, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # convert to dataframe\n",
    "    df = pd.DataFrame(json_data)\n",
    "\n",
    "    # save as parquet\n",
    "    df.to_parquet(parquet_path)\n",
    "\n",
    "# convert all json files to parquet\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in tqdm(files):\n",
    "        if file.endswith(\".json\"):\n",
    "            json_path = os.path.join(root, file)\n",
    "            parquet_path = json_path.replace(\".json\", \".parquet\")\n",
    "            convert_json_to_parquet(json_path, parquet_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification que la transcription s'est bien faite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>id</th>\n",
       "      <th>formality</th>\n",
       "      <th>siren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-14T02:50:52+02:00</td>\n",
       "      <td>63dddf50d1ff8689bd18e053</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>532377751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-14T02:50:51+02:00</td>\n",
       "      <td>63ac3caec67bc86d9f0dea9b</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>532377595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-15T18:11:51+02:00</td>\n",
       "      <td>63ac3cace3573db1980ed335</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>532377355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-06T11:18:54+02:00</td>\n",
       "      <td>63ac3caaf98dfe66e208d515</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>532377090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-02T01:44:28+02:00</td>\n",
       "      <td>63dddf54474db94e781b2313</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>532376811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2023-05-14T03:10:15+02:00</td>\n",
       "      <td>63cfb0cb037fe8e60c027305</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>533576898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2023-05-14T03:10:19+02:00</td>\n",
       "      <td>63dde09fd1ff8689bd18ffe7</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>533577292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2023-05-14T03:10:21+02:00</td>\n",
       "      <td>63dde0a412889021a71a99b3</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>533576419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2023-06-01T20:24:54+02:00</td>\n",
       "      <td>63ac43fae3573db1980f0ec7</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>533576724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2023-06-02T02:11:38+02:00</td>\n",
       "      <td>63dde09fd1ff8689bd18ffe9</td>\n",
       "      <td>{'content': {'exploitation': None, 'formeExerc...</td>\n",
       "      <td>533577359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       updatedAt                        id  \\\n",
       "0      2023-05-14T02:50:52+02:00  63dddf50d1ff8689bd18e053   \n",
       "1      2023-05-14T02:50:51+02:00  63ac3caec67bc86d9f0dea9b   \n",
       "2      2023-06-15T18:11:51+02:00  63ac3cace3573db1980ed335   \n",
       "3      2023-07-06T11:18:54+02:00  63ac3caaf98dfe66e208d515   \n",
       "4      2023-06-02T01:44:28+02:00  63dddf54474db94e781b2313   \n",
       "...                          ...                       ...   \n",
       "99995  2023-05-14T03:10:15+02:00  63cfb0cb037fe8e60c027305   \n",
       "99996  2023-05-14T03:10:19+02:00  63dde09fd1ff8689bd18ffe7   \n",
       "99997  2023-05-14T03:10:21+02:00  63dde0a412889021a71a99b3   \n",
       "99998  2023-06-01T20:24:54+02:00  63ac43fae3573db1980f0ec7   \n",
       "99999  2023-06-02T02:11:38+02:00  63dde09fd1ff8689bd18ffe9   \n",
       "\n",
       "                                               formality      siren  \n",
       "0      {'content': {'exploitation': None, 'formeExerc...  532377751  \n",
       "1      {'content': {'exploitation': None, 'formeExerc...  532377595  \n",
       "2      {'content': {'exploitation': None, 'formeExerc...  532377355  \n",
       "3      {'content': {'exploitation': None, 'formeExerc...  532377090  \n",
       "4      {'content': {'exploitation': None, 'formeExerc...  532376811  \n",
       "...                                                  ...        ...  \n",
       "99995  {'content': {'exploitation': None, 'formeExerc...  533576898  \n",
       "99996  {'content': {'exploitation': None, 'formeExerc...  533577292  \n",
       "99997  {'content': {'exploitation': None, 'formeExerc...  533576419  \n",
       "99998  {'content': {'exploitation': None, 'formeExerc...  533576724  \n",
       "99999  {'content': {'exploitation': None, 'formeExerc...  533577359  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all parquet files paths\n",
    "parquets = [os.path.join(base_path,f) for f in os.listdir(base_path) if f.endswith(\".parquet\")]\n",
    "\n",
    "# choose a random one and read it\n",
    "\n",
    "rand = np.random.randint(0, len(parquets))\n",
    "\n",
    "df = pd.read_parquet(parquets[rand])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage de données par entreprise à des données par établissement\n",
    "\n",
    "Pour pouvoir avoir des filtres géographiques, on a besoin d'avoir le détail par établissement.\n",
    "\n",
    "Or les données sont regroupées pour l'instant à l'échelle d'une entreprise. \n",
    "\n",
    "On cherche donc la meilleure manière de faire ce filtre, on peut se référer à la [documentation de l'inpi](https://www.inpi.fr/sites/default/files/documentation_technique_API_formalit%C3%A9s_v2.5.pdf) pour voir comment sont structurées les données.\n",
    "\n",
    "Sur le site, de l'INPI, on peut aussi consulter leur [dictionnaire des données](https://www.inpi.fr/sites/default/files/Dictionnaire_de_donnees_2023_avril.xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour convertir les données associées à une entreprise en json pour pouvoir parser facilement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            if obj.dtype == object:\n",
    "                # Handle NumPy array with dtype=object\n",
    "                return obj.tolist()\n",
    "            else:\n",
    "                # Handle other NumPy arrays\n",
    "                return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def convert_np_to_list(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {key: convert_np_to_list(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_np_to_list(item) for item in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "    \n",
    "\n",
    "\n",
    "# Conversion and saving\n",
    "with open(\"temp.json\", \"w\") as f:\n",
    "\n",
    "    # Choose a random row\n",
    "    rand = np.random.randint(0, len(df))\n",
    "\n",
    "    # Convert numpy arrays to lists recursively\n",
    "    converted_text = convert_np_to_list(df.iloc[rand].to_dict())\n",
    "\n",
    "    # Save output as indented JSON\n",
    "    json.dump(converted_text, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions pour parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour une entrepise sans établissement secondaire, retourne les informations de l'entreprise\n",
    "def parse_etablissement(etablissementPrincipal,diffusionCommerciale,nomCommercial,codeApe):\n",
    "\n",
    "    # certaines entreprises n'ont pas de nom commercial (ex : siren 949 299 903)\n",
    "    try :\n",
    "        siret = etablissementPrincipal[\"descriptionEtablissement\"][\"siret\"]\n",
    "    except :\n",
    "        return None\n",
    "\n",
    "    # certaines entreprises n'ont pas d'adresse ex : siren 950567479\n",
    "    try :\n",
    "        adresse_base = etablissementPrincipal[\"adresse\"]\n",
    "\n",
    "        # Check for None values and handle them\n",
    "        elements = [adresse_base.get(key, \"\") for key in [\"numVoie\", \"typeVoie\", \"voie\", \"codePostal\", \"commune\"]]\n",
    "\n",
    "        # Construct the address string, skipping None values\n",
    "        adresse = \" \".join(elements) if None not in elements else \"\"\n",
    "    except :\n",
    "        return None\n",
    "\n",
    "    try :\n",
    "        codeInseeCommune = adresse_base[\"codeInseeCommune\"]\n",
    "    except :\n",
    "        return None\n",
    "\n",
    "    return {siret: {\"nomCommercial\": nomCommercial, \"adresse\": adresse, \"codeInseeCommune\": codeInseeCommune, \"codeApe\": codeApe, \"diffusionCommerciale\": diffusionCommerciale}}\n",
    "\n",
    "# liste des codes rolePourEntreprise d'établissement fermé\n",
    "rolePourEntreprise_fermes = [\"11\",\"12\",\"13\",\"14\",\"15\",\"16\"]\n",
    "\n",
    "\n",
    "# pour une entreprise avec établissement secondaire, retourne les informations de chaque établissement\n",
    "def parse_etablissements_secondaires(autresEtablissements, diffusionCommerciale, formality):\n",
    "\n",
    "    # one dict to store them all\n",
    "    etablissements = {}\n",
    "\n",
    "    # pour chaque établissement\n",
    "    for etablissement in autresEtablissements:\n",
    "        \n",
    "        # si l'établissement est fermé, on ne le prend pas en compte\n",
    "        if etablissement[\"descriptionEtablissement\"][\"rolePourEntreprise\"] in rolePourEntreprise_fermes:\n",
    "            continue\n",
    "\n",
    "        # etablissement ouvert\n",
    "        else :\n",
    "\n",
    "            try :\n",
    "    \n",
    "                adresse_base = etablissement[\"adresse\"]\n",
    "\n",
    "                # Check for None values and handle them\n",
    "                elements = [adresse_base.get(key, \"\") for key in [\"numVoie\", \"typeVoie\", \"voie\", \"codePostal\", \"commune\"]]\n",
    "\n",
    "                # Construct the address string, skipping None values\n",
    "                adresse = \" \".join(elements) if None not in elements else \"\"\n",
    "\n",
    "\n",
    "            except :\n",
    "\n",
    "                adresse = None\n",
    "\n",
    "            # si l'adresse n'est pas en France, on ne la prend pas en compte\n",
    "            try :\n",
    "                codeInseeCommune = etablissement[\"adresse\"][\"codeInseeCommune\"]\n",
    "            except :\n",
    "                codeInseeCommune = None\n",
    "\n",
    "            siret = etablissement[\"descriptionEtablissement\"][\"siret\"]\n",
    "\n",
    "            codeApe = formality[\"content\"][\"personneMorale\"][\"identite\"][\"entreprise\"][\"codeApe\"]\n",
    "            \n",
    "            nomCommercial = etablissement[\"descriptionEtablissement\"][\"nomCommercial\"]\n",
    "\n",
    "            if nomCommercial == None:\n",
    "                nomCommercial = formality[\"content\"][\"personneMorale\"][\"identite\"][\"entreprise\"][\"denomination\"]\n",
    "\n",
    "            diffusionCommerciale = formality[\"diffusionCommerciale\"]\n",
    "        \n",
    "            etablissements[siret] = {\"nomCommercial\": nomCommercial, \"adresse\": adresse, \"codeInseeCommune\": codeInseeCommune, \"codeApe\": codeApe, \"diffusionCommerciale\": diffusionCommerciale}\n",
    "\n",
    "    return etablissements\n",
    "\n",
    "# retourne les informations de l'entreprise concernée par la cessation\n",
    "def parse_formality(formality):\n",
    "\n",
    "\n",
    "    # personne morale\n",
    "    if formality[\"content\"][\"personneMorale\"] == None:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # cas 1 : entreprise sans établissement secondaire\n",
    "    if (not isinstance(formality[\"content\"][\"personneMorale\"][\"autresEtablissements\"],np.ndarray)) and formality[\"content\"][\"personneMorale\"][\"etablissementPrincipal\"] != None:\n",
    "\n",
    "        codeApe = formality[\"content\"][\"personneMorale\"]['identite'][\"entreprise\"][\"codeApe\"]\n",
    "        denomination = formality[\"content\"][\"personneMorale\"][\"identite\"][\"entreprise\"][\"denomination\"]\n",
    "        diffusionCommerciale = formality[\"diffusionCommerciale\"]\n",
    "\n",
    "        return parse_etablissement(formality[\"content\"][\"personneMorale\"][\"etablissementPrincipal\"],diffusionCommerciale,denomination,codeApe)\n",
    "    \n",
    "    \n",
    "    # cas 2 : entreprise avec établissement secondaire\n",
    "    elif isinstance(formality[\"content\"][\"personneMorale\"][\"autresEtablissements\"],np.ndarray) :\n",
    "\n",
    "\n",
    "        return parse_etablissements_secondaires(formality[\"content\"][\"personneMorale\"][\"autresEtablissements\"], formality[\"diffusionCommerciale\"],formality)\n",
    "\n",
    "\n",
    "    # cas 3 : entreprise avec mauvaise saisie : ni établissement principal, ni établissement secondaire\n",
    "    # ex : siren 949759906\n",
    "    else :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:17<00:00, 5759.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate 10000 random numbers\n",
    "rand = np.random.randint(0, len(df), 100000)\n",
    "\n",
    "# for each random number, parse the content and create a dataframe\n",
    "df_parsed = pd.DataFrame(columns=[\"siret\", \"nomCommercial\", \"adresse\", \"codeInseeCommune\", \"codeApe\", \"diffusionCommerciale\",\"row\"])\n",
    "\n",
    "for i in tqdm(rand):\n",
    "\n",
    "    row = df.iloc[i]\n",
    "\n",
    "    try :\n",
    "        parsed = parse_formality(row[\"formality\"])\n",
    "    except :\n",
    "        print(\"Error on row {}\".format(i))\n",
    "        break\n",
    "\n",
    "    if parsed == None:\n",
    "        continue\n",
    "\n",
    "    # concatenate the row number to the parsed data\n",
    "    for key, value in parsed.items():\n",
    "        value[\"row\"] = i\n",
    "\n",
    "    # append to the dataframe\n",
    "    pd.concat([df_parsed, pd.DataFrame.from_dict(parsed, orient=\"index\")], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'53249469700016': {'nomCommercial': 'TRISTANA',\n",
       "  'adresse': '24 BD DU GENERAL LECLERC 22520 BINIC-ETABLES-SUR-MER',\n",
       "  'codeInseeCommune': '22055',\n",
       "  'codeApe': '9602B',\n",
       "  'diffusionCommerciale': True}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_row = 9817\n",
    "\n",
    "# Conversion and saving\n",
    "with open(\"temp.json\", \"w\") as f:\n",
    "\n",
    "\n",
    "    # Convert numpy arrays to lists recursively\n",
    "    converted_text = convert_np_to_list(df.iloc[error_row].to_dict())\n",
    "\n",
    "    # Save output as indented JSON\n",
    "    json.dump(converted_text, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "parse_formality(df.iloc[error_row][\"formality\"])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin du debugging : on enlève le temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('temp.json'):\n",
    "    os.remove('temp.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test sur un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def parse_parquet(parquet_path):\n",
    "\n",
    "    # lecture du parquet\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    # liste des résultats\n",
    "    results = []\n",
    "\n",
    "    # pour chaque entreprise \n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        # parse the formality\n",
    "        parsed = parse_formality(row[\"formality\"])\n",
    "\n",
    "        if parsed == None or parsed == {}:\n",
    "            continue    \n",
    "\n",
    "        else :\n",
    "            # extend the dict with the parsed data\n",
    "            results.append(parsed)\n",
    "\n",
    "\n",
    "    # converts to dataframe\n",
    "    df = pd.DataFrame([(key, *value.values()) for dct in results for key, value in dct.items()], columns=[\"siret\", \"nomCommercial\", \"adresse\", \"codeInseeCommune\", \"codeApe\", \"diffusionCommerciale\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# choose a random parquet file\n",
    "rand = np.random.randint(0, len(parquets))\n",
    "\n",
    "# parse it\n",
    "parse_parquet(parquets[rand])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing de tous les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [31:54<00:00,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min, sys: 7min 29s, total: 28min 29s\n",
      "Wall time: 31min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loops over all parquet files and parse them\n",
    "for parquet in tqdm(parquets):\n",
    "    df = parse_parquet(parquet)\n",
    "    \n",
    "    # save as parquet\n",
    "    df.to_parquet(parquet.replace(\".parquet\", \"_parsed.parquet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un seul parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de parquets parsés : 241\n"
     ]
    }
   ],
   "source": [
    "parsed_parquets = [os.path.join(base_path,f) for f in os.listdir(base_path) if f.endswith(\"_parsed.parquet\")]\n",
    "\n",
    "print(\"Nombre de parquets parsés : {}\".format(len(parsed_parquets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:03<00:00, 71.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.8 s, sys: 2.14 s, total: 8.93 s\n",
      "Wall time: 9.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "# concat all parsed parquets into a single parquet file\n",
    "df = pd.concat([pd.read_parquet(parquet) for parquet in tqdm(parsed_parquets)])\n",
    "\n",
    "# save as parquet\n",
    "df.to_parquet(os.path.join(base_path, \"final_dataset_parsed.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de la taille pris par les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids des jsons : 108100.5 Mo\n",
      "Poids des parquets originaux : 8483.95 Mo\n",
      "Poids des parquets parsés : 712.89 Mo\n",
      "Poids du parquet final : 346.08 Mo\n"
     ]
    }
   ],
   "source": [
    "jsons = [os.path.join(base_path,f) for f in os.listdir(base_path) if f.endswith(\".json\")]\n",
    "parsed_parquets = [os.path.join(base_path,f) for f in os.listdir(base_path) if f.endswith(\"_parsed.parquet\")]\n",
    "parquets = [os.path.join(base_path,f) for f in os.listdir(base_path) if f.endswith(\".parquet\")]\n",
    "original_parquets = [parquet for parquet in parquets if parquet not in parsed_parquets]\n",
    "\n",
    "print(\"Poids des jsons : {} Mo\".format(round(sum([os.path.getsize(json) for json in jsons]) / 1000000, 2)))\n",
    "\n",
    "print(\"Poids des parquets originaux : {} Mo\".format(round(sum([os.path.getsize(parquet) for parquet in original_parquets]) / 1000000, 2)))\n",
    "\n",
    "print(\"Poids des parquets parsés : {} Mo\".format(round(sum([os.path.getsize(parquet) for parquet in parsed_parquets]) / 1000000, 2)))\n",
    "\n",
    "print(\"Poids du parquet final : {} Mo\".format(round(os.path.getsize(os.path.join(base_path, \"final_dataset_parsed.parquet\")) / 1000000, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siret</th>\n",
       "      <th>nomCommercial</th>\n",
       "      <th>adresse</th>\n",
       "      <th>codeInseeCommune</th>\n",
       "      <th>codeApe</th>\n",
       "      <th>diffusionCommerciale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40825446400014</td>\n",
       "      <td>SCI GRAISSAC</td>\n",
       "      <td>8 RUE DU ROCHER 75008 PARIS 8</td>\n",
       "      <td>75108</td>\n",
       "      <td>6820B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40825448000010</td>\n",
       "      <td>LE SAINTES SCARBES</td>\n",
       "      <td>10 PL SAINTES SCARBES 31000 TOULOUSE</td>\n",
       "      <td>31555</td>\n",
       "      <td>553A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40825449800020</td>\n",
       "      <td>HELIOS PEINTURE</td>\n",
       "      <td>13 RUE DE LA VICTOIRE 93150 LE BLANC-MESNIL</td>\n",
       "      <td>93007</td>\n",
       "      <td>454J</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40825480300013</td>\n",
       "      <td>SCP VETERINAIRES DUBOST F ET TARDIEUX MC</td>\n",
       "      <td></td>\n",
       "      <td>13110</td>\n",
       "      <td>7500Z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40825387000013</td>\n",
       "      <td>IC 3A</td>\n",
       "      <td>1 RUE ROBERT FOURNERON 07400 LE TEIL</td>\n",
       "      <td>07319</td>\n",
       "      <td>742C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12799</th>\n",
       "      <td>78849706300016</td>\n",
       "      <td>COBAMET</td>\n",
       "      <td>92 RUE CAROLINE FOLLET 80160 CONTY</td>\n",
       "      <td>80211</td>\n",
       "      <td>4332B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12800</th>\n",
       "      <td>78849721200019</td>\n",
       "      <td>MASSAGE CHINOIS 6</td>\n",
       "      <td>6 RUE DE LANCRY 75010 PARIS 10</td>\n",
       "      <td>75110</td>\n",
       "      <td>9604Z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12801</th>\n",
       "      <td>78849780800014</td>\n",
       "      <td>ID'S WORKS</td>\n",
       "      <td>3 CHE DE LA POUPETTERIE 86800 SEVRES-ANXAUMONT</td>\n",
       "      <td>86261</td>\n",
       "      <td>7311Z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12802</th>\n",
       "      <td>78849702200012</td>\n",
       "      <td>LES BEAUX PINS</td>\n",
       "      <td>14 RUE DES BRUYERES 33450 SAINT-LOUBES</td>\n",
       "      <td>33433</td>\n",
       "      <td>6820B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803</th>\n",
       "      <td>78849737800018</td>\n",
       "      <td>CUSSET SPEED PERMIS</td>\n",
       "      <td>103 RUE PIERRE VOYANT 69100 VILLEURBANNE</td>\n",
       "      <td>69266</td>\n",
       "      <td>8553Z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7831781 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                siret                             nomCommercial  \\\n",
       "0      40825446400014                              SCI GRAISSAC   \n",
       "1      40825448000010                        LE SAINTES SCARBES   \n",
       "2      40825449800020                           HELIOS PEINTURE   \n",
       "3      40825480300013  SCP VETERINAIRES DUBOST F ET TARDIEUX MC   \n",
       "4      40825387000013                                     IC 3A   \n",
       "...               ...                                       ...   \n",
       "12799  78849706300016                                   COBAMET   \n",
       "12800  78849721200019                         MASSAGE CHINOIS 6   \n",
       "12801  78849780800014                                ID'S WORKS   \n",
       "12802  78849702200012                            LES BEAUX PINS   \n",
       "12803  78849737800018                       CUSSET SPEED PERMIS   \n",
       "\n",
       "                                              adresse codeInseeCommune  \\\n",
       "0                       8 RUE DU ROCHER 75008 PARIS 8            75108   \n",
       "1                10 PL SAINTES SCARBES 31000 TOULOUSE            31555   \n",
       "2         13 RUE DE LA VICTOIRE 93150 LE BLANC-MESNIL            93007   \n",
       "3                                                                13110   \n",
       "4                1 RUE ROBERT FOURNERON 07400 LE TEIL            07319   \n",
       "...                                               ...              ...   \n",
       "12799              92 RUE CAROLINE FOLLET 80160 CONTY            80211   \n",
       "12800                  6 RUE DE LANCRY 75010 PARIS 10            75110   \n",
       "12801  3 CHE DE LA POUPETTERIE 86800 SEVRES-ANXAUMONT            86261   \n",
       "12802          14 RUE DES BRUYERES 33450 SAINT-LOUBES            33433   \n",
       "12803        103 RUE PIERRE VOYANT 69100 VILLEURBANNE            69266   \n",
       "\n",
       "      codeApe  diffusionCommerciale  \n",
       "0       6820B                  True  \n",
       "1        553A                  True  \n",
       "2        454J                  True  \n",
       "3       7500Z                  True  \n",
       "4        742C                  True  \n",
       "...       ...                   ...  \n",
       "12799   4332B                  True  \n",
       "12800   9604Z                  True  \n",
       "12801   7311Z                  True  \n",
       "12802   6820B                  True  \n",
       "12803   8553Z                  True  \n",
       "\n",
       "[7831781 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(os.path.join(base_path, \"final_dataset_parsed.parquet\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean du parquet final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes : 7831781\n",
      "Nombre de lignes uniques : 7831770\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "\n",
    "print(\"Nombre de lignes : {}\".format(len(df)))\n",
    "\n",
    "print(\"Nombre de lignes uniques : {}\".format(len(df.drop_duplicates())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().to_parquet(\"../Données nationales/RNE.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siret</th>\n",
       "      <th>nomCommercial</th>\n",
       "      <th>adresse</th>\n",
       "      <th>codeInseeCommune</th>\n",
       "      <th>codeApe</th>\n",
       "      <th>diffusionCommerciale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>32522172900016</td>\n",
       "      <td>SA SBME INTERMARCHE</td>\n",
       "      <td>37 RUE HERVE DE GUEBRIANT 29800 LANDERNEAU</td>\n",
       "      <td>29103</td>\n",
       "      <td>4711F</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             siret        nomCommercial  \\\n",
       "57  32522172900016  SA SBME INTERMARCHE   \n",
       "\n",
       "                                       adresse codeInseeCommune codeApe  \\\n",
       "57  37 RUE HERVE DE GUEBRIANT 29800 LANDERNEAU            29103   4711F   \n",
       "\n",
       "    diffusionCommerciale  \n",
       "57                  True  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check siret 45132133500023 (Carrefour)\n",
    "\n",
    "df[df[\"siret\"] == \"32522172900016\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout 24/01 : dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rne = pd.read_parquet('../Données nationales/RNE.parquet')\n",
    "\n",
    "def is_digit(x):\n",
    "\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "df_rne[\"is_digit\"] = df_rne.siret.apply(is_digit)\n",
    "\n",
    "\n",
    "df_rne = df_rne[df_rne.is_digit != False].drop([\"is_digit\"],axis=1)\n",
    "df_rne[\"siret\"] = df_rne.siret.astype(np.int64)\n",
    "\n",
    "df_rne.to_parquet(\"../Données nationales/RNE.parquet\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout 2 : bons codes  naf (abandonnés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts 6420Z to 64.20Z\n",
    "\n",
    "df_rne = pd.read_parquet('../Données nationales/RNE.parquet')\n",
    "\n",
    "\n",
    "def convert_format(x):\n",
    "\n",
    "    x = str(x)\n",
    "\n",
    "    return x[:2]+'.'+x[2:]\n",
    "\n",
    "\n",
    "df_rne[\"codeApe\"] = df_rne[\"codeApe\"].apply(convert_format)\n",
    "\n",
    "df_rne.to_parquet(\"../Données nationales/RNE.parquet\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rne = pd.read_parquet('../Données nationales/RNE.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rne.columns = ['siret', 'nomCommercial', 'adresse', 'codeInseeCommune', 'codeApe',\n",
    "       'diffusionCommerciale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rne.to_parquet(\"../Données nationales/RNE.parquet\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_zone_de_chalandise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
